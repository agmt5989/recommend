{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 8 total categories.\n",
      "There are 486 total images.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_files       \n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "\n",
    "# define function to load train, test, and validation datasets\n",
    "def load_dataset(path):\n",
    "    data = load_files(path)\n",
    "    data_files = np.array(data['filenames'])\n",
    "    data_targets = data['target']\n",
    "    return data_files, data_targets\n",
    "\n",
    "\n",
    "train_files, train_targets = load_dataset('data/')\n",
    "\n",
    "\n",
    "# load list of dog names\n",
    "names = [item[5:-1] for item in sorted(glob(\"data/*/\"))]\n",
    "\n",
    "# print statistics about the dataset\n",
    "print('There are %d total categories.' % len(names))\n",
    "print('There are %d total images.' % len(train_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fifty',\n",
       " 'five',\n",
       " 'five hundred',\n",
       " 'one hundred',\n",
       " 'one thousand',\n",
       " 'ten',\n",
       " 'twenty',\n",
       " 'two hundred']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions\n",
    "from keras.preprocessing import image\n",
    "from keras.layers import Input, Flatten, Dense\n",
    "from keras.models import Model\n",
    "from tqdm import tqdm\n",
    "from PIL import ImageFile    \n",
    "\n",
    "\n",
    "def path_to_tensor(img_path):\n",
    "    # loads RGB image as PIL.Image.Image type\n",
    "    img = image.load_img(img_path, target_size=(299, 299))\n",
    "    # convert PIL.Image.Image type to 3D tensor with shape (299, 299, 3)\n",
    "    x = image.img_to_array(img)\n",
    "    # convert 3D tensor to 4D tensor with shape (1, 299, 299, 3) and return 4D tensor\n",
    "    return np.expand_dims(x, axis=0)\n",
    "\n",
    "def paths_to_tensor(img_paths):\n",
    "    list_of_tensors = [path_to_tensor(img_path) for img_path in tqdm(img_paths)]\n",
    "    return np.vstack(list_of_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 486/486 [00:06<00:00, 80.11it/s]\n"
     ]
    }
   ],
   "source": [
    "ImageFile.LOAD_TRUNCATED_IMAGES = True                 \n",
    "# pre-process the train data for Keras\n",
    "train_tensors = paths_to_tensor(train_files).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(299, 299, 3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tensors[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from skimage.feature import hog\n",
    "\n",
    "\n",
    "class RGB2GrayTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Convert an array of RGB images to grayscale\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"returns itself\"\"\"\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        \"\"\"perform the transformation and return an array\"\"\"\n",
    "        return np.array([skimage.color.rgb2gray(img) for img in X])\n",
    "\n",
    "\n",
    "class HogTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Expects an array of 2d arrays (1 channel images)\n",
    "    Calculates hog features for each img\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, y=None, orientations=9,\n",
    "                 pixels_per_cell=(8, 8),\n",
    "                 cells_per_block=(3, 3), block_norm='L2-Hys'):\n",
    "        self.y = y\n",
    "        self.orientations = orientations\n",
    "        self.pixels_per_cell = pixels_per_cell\n",
    "        self.cells_per_block = cells_per_block\n",
    "        self.block_norm = block_norm\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "\n",
    "        def local_hog(X):\n",
    "            return hog(X,\n",
    "                       orientations=self.orientations,\n",
    "                       pixels_per_cell=self.pixels_per_cell,\n",
    "                       cells_per_block=self.cells_per_block,\n",
    "                       block_norm=self.block_norm)\n",
    "\n",
    "        try: # parallel\n",
    "            return np.array([local_hog(img) for img in X])\n",
    "        except:\n",
    "            return np.array([local_hog(img) for img in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import skimage\n",
    "\n",
    "# create an instance of each transformer\n",
    "grayify = RGB2GrayTransformer()\n",
    "hogify = HogTransformer(\n",
    "    pixels_per_cell=(8, 8),\n",
    "    cells_per_block=(2,2),\n",
    "    orientations=9,\n",
    "    block_norm='L2-Hys'\n",
    ")\n",
    "scalify = StandardScaler()\n",
    "\n",
    "# call fit_transform on each transform converting X_train step by step\n",
    "X_train_gray = grayify.fit_transform(train_tensors)\n",
    "X_train_hog = hogify.fit_transform(X_train_gray)\n",
    "scalify.fit(X_train_hog)\n",
    "X_train_prepared = scalify.transform(X_train_hog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9446193523114476\n"
     ]
    }
   ],
   "source": [
    "outer_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=5)\n",
    "\n",
    "model = SVC()\n",
    "model.fit(X_train_prepared, train_targets)\n",
    "# Nested CV with parameter optimization\n",
    "nested_lin_1 = cross_val_score(model, X=X_train_prepared, y=train_targets,\n",
    "                               scoring='accuracy', cv=outer_cv)\n",
    "print(nested_lin_1.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96226415, 0.94230769, 0.92307692, 0.93877551, 0.97916667,\n",
       "       0.89583333, 0.93617021, 0.95652174, 0.95652174, 0.95555556])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nested_lin_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['finalized_model4.sav']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "filename = 'finalized_model4.sav'\n",
    "joblib.dump(model, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Scaler1.sav']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'Scaler1.sav'\n",
    "joblib.dump(scalify, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
